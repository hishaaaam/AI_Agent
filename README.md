# ğŸ¤– Open-Source AI Agent Pro (Hugging Face)

A **production-ready AI Agent** built entirely with **open-source Hugging Face models**.
It can understand user queries, decide when to call tools, and respond intelligently â€” all wrapped in a **professional, interactive Streamlit UI**.

ğŸ”— **Live Demo (Hugging Face Space):**
ğŸ‘‰ https://huggingface.co/spaces/hishaaaam/AIagent

---

## âœ¨ Features

* ğŸ§  Open-source LLM (no OpenAI dependency)
* ğŸ”§ Function / Tool Calling (Calculator + Weather)
* ğŸ’¬ Persistent Chat Memory
* âš¡ Optimized for Hugging Face Spaces (CPU friendly)
* ğŸ¨ Netflix-style professional UI
* ğŸš€ Cached model loading for fast performance
* ğŸ“± Mobile-responsive interface
* ğŸ§© Clean modular architecture
* ğŸ†“ Fully free and self-hostable

---

## ğŸ—ï¸ Architecture

```
User â†’ Streamlit UI â†’ LLM â†’ Tool Decision â†’ Function Execution â†’ Final Response
```

**Flow:**

1. Receives user input
2. LLM decides whether to call a tool
3. Tool executes
4. Agent returns formatted answer

---

## ğŸ“ Project Structure

```
ai-agent-hf-pro/
â”‚
â”œâ”€â”€ app.py              # Streamlit UI
â”œâ”€â”€ agent.py            # Agent brain + routing
â”œâ”€â”€ tools.py            # External functions
â”œâ”€â”€ config.py           # Model configuration
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .streamlit/
    â””â”€â”€ config.toml
```

---

## ğŸ§  Model Used

**Default:** `TinyLlama/TinyLlama-1.1B-Chat-v1.0`

**Why this model?**

* âœ… Lightweight
* âœ… Fast on CPU
* âœ… Works on Hugging Face free tier
* âœ… Good instruction following

You can easily swap models in `config.py`.

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/your-username/ai-agent-hf-pro.git
cd ai-agent-hf-pro
```

---

### 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

### 3ï¸âƒ£ Run the App

```bash
streamlit run app.py
```

App will open at:

```
http://localhost:8501
```

---

## ğŸš€ Hugging Face Spaces Deployment

This project is **Spaces-ready**.

### Recommended Settings

* **SDK:** Streamlit
* **Hardware:** CPU Basic
* **Python:** 3.10

Then simply upload the repository files.

---

## ğŸ§ª Example Prompts

Try these in the chat:

```
What is 45 * 22?
Weather in Mumbai
Explain machine learning simply
```

---

## ğŸ”§ Available Tools

### ğŸ§® Calculator

Evaluates mathematical expressions.

**Example**

```
User: What is 234 * 56?
Agent â†’ calculator â†’ result
```

---

### ğŸŒ¤ï¸ Weather (Mock)

Returns sample weather data.

**Example**

```
User: Weather in Delhi
Agent â†’ get_weather â†’ result
```

> ğŸ”® You can easily connect a real weather API.

---

## âš¡ Performance Optimizations

This project includes:

* `@st.cache_resource` model caching
* CPU-friendly lightweight model
* Low temperature for stable routing
* Lightweight UI rendering
* Hugging Face Spaces configuration

---

## ğŸ¨ UI Highlights

* Glassmorphism chat bubbles
* Dark professional theme
* Typing spinner
* Persistent conversation memory
* Wide responsive layout
* Clean modern typography

---

## ğŸ”„ How Tool Calling Works

The LLM is instructed to output in a strict format:

```
TOOL: calculator | expression=2+2
```

The agent then:

1. Parses the tool name
2. Executes the function
3. Returns the result

This keeps the system:

* simple
* transparent
* fully open-source

---

## ğŸ§© Future Improvements

Planned upgrades:

* [ ] Streaming responses
* [ ] Multi-tool reasoning
* [ ] RAG knowledge base
* [ ] Voice input
* [ ] LangGraph agent loop
* [ ] Real weather API
* [ ] Docker deployment

---

## ğŸ¤ Contributing

Contributions are welcome!

You can help improve:

* UI/UX
* model performance
* new tools
* memory system

Feel free to fork and submit a PR.

---

## ğŸ“œ License

MIT License â€” free to use and modify.

---

## ğŸ‘¤ Author

**Hisham Hidayathulla**

If you found this useful, consider â­ starring the repo!

---

**Built with â¤ï¸ using Hugging Face + Streamlit**
